{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Chat Bot code workflow**"
      ],
      "metadata": {
        "id": "h7U63GkBAVSH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#libraries and Configuration\n",
        "\n",
        "import os\n",
        "import asyncio\n",
        "from typing import List, Dict, Any\n",
        "\n",
        "from fastapi import FastAPI, Request, HTTPException\n",
        "from fastapi.responses import HTMLResponse\n",
        "from fastapi.templating import Jinja2Templates\n",
        "from pydantic import BaseModel\n",
        "\n",
        "from langchain_core.documents import Document\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_google_vertexai import VertexAIEmbeddings # Import VertexAIEmbeddings\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain_google_vertexai import VertexAI, VertexVectorStore # Import VertexVectorStore\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_community.document_loaders import PyPDFLoader # Keep for reference, but we'll use GCS for scraped data\n",
        "from google.cloud import storage\n",
        "from langchain_openai import ChatOpenAI # Import ChatOpenAI for GPT-4\n",
        "\n",
        "\n",
        "# --- GCP Configuration ---\n",
        "PROJECT_ID = \" \"\n",
        "REGION = \" \"\n",
        "GCS_BUCKET_NAME = \" \"\n",
        "# The GCS folder where scraped HTML/text files are stored\n",
        "GCS_SCRAPED_DATA_PREFIX = \" \"\n",
        "# Vertex AI Search App ID for your data store\n",
        "VERTEX_SEARCH_DATASTORE_ID = \"your-vertex-ai-search-datastore-id\"\n",
        "# Vertex AI Vector Search Index ID and Endpoint ID\n",
        "VERTEX_VECTOR_SEARCH_INDEX_ID = \"your-vertex-vector-search-index-id\"\n",
        "VERTEX_VECTOR_SEARCH_ENDPOINT_ID = \"your-vertex-vector-search-endpoint-id\""
      ],
      "metadata": {
        "id": "NjB4nbPWDHrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. **Webscraping**"
      ],
      "metadata": {
        "id": "9U4cITn9AiQ1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tX_AYrJ-ATMB"
      },
      "outputs": [],
      "source": [
        "from google.cloud import storage\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import os\n",
        "\n",
        "\n",
        "PROJECT_ID = \" \"\n",
        "GCS_BUCKET_NAME = \" \"\n",
        "\n",
        "# Authenticate implicitly if running on a GCP service with service account permissions\n",
        "# Otherwise, you might need to set GOOGLE_APPLICATION_CREDENTIALS environment variable\n",
        "# pointing to your service account key file.\n",
        "# os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = \"/path/to/your/key.json\"\n",
        "\n",
        "def scrape_website_and_upload_to_gcs(url, gcs_path_prefix=\"scraped_data/\"):\n",
        "    \"\"\"\n",
        "    Scrapes a given URL, extracts text, and uploads it to Google Cloud Storage.\n",
        "\n",
        "    Args:\n",
        "        url (str): The URL to scrape.\n",
        "        gcs_path_prefix (str): The GCS folder path where the file will be stored.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        response = requests.get(url)\n",
        "        response.raise_for_status()  # Raise an exception for HTTP errors\n",
        "\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "        # Example: Extract all text from paragraphs. Adjust as per your scraping needs.\n",
        "        scraped_text = ' '.join([p.get_text() for p in soup.find_all('p')])\n",
        "\n",
        "        if not scraped_text:\n",
        "            print(f\"No significant text found for {url}. Skipping upload.\")\n",
        "            return\n",
        "\n",
        "        # Define the GCS file name. You might want to sanitize the URL for this.\n",
        "        file_name = url.split(\"//\")[-1].replace(\"/\", \"_\").replace(\".\", \"_\") + \".txt\"\n",
        "        destination_blob_name = os.path.join(gcs_path_prefix, file_name)\n",
        "\n",
        "        storage_client = storage.Client(project=PROJECT_ID)\n",
        "        bucket = storage_client.bucket(GCS_BUCKET_NAME)\n",
        "        blob = bucket.blob(destination_blob_name)\n",
        "\n",
        "        blob.upload_from_string(scraped_text, content_type='text/plain')\n",
        "        print(f\"Uploaded scraped data from {url} to gs://{GCS_BUCKET_NAME}/{destination_blob_name}\")\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Error scraping {url}: {e}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    urls_to_scrape = [\n",
        "        \"https://www.example.com/page1\",\n",
        "        \"https://www.example.org/another-page\",\n",
        "        # Add more URLs as needed\n",
        "    ]\n",
        "\n",
        "    for url in urls_to_scrape:\n",
        "        scrape_website_and_upload_to_gcs(url)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Splitting**, **Chunking**, **Embeddings**"
      ],
      "metadata": {
        "id": "M33y_budBg6R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Text Splitter for RAG\n",
        "# Chunk size and overlap are crucial for RAG performance\n",
        "# Adjust these based on the nature of your e-commerce product descriptions.\n",
        "# For detailed product info, larger chunks might be needed.\n",
        "# For short Q&A, smaller chunks.\n",
        "CHUNK_SIZE = 1000 # Characters per chunk\n",
        "CHUNK_OVERLAP = 200 # Overlap between chunks to maintain context\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=CHUNK_SIZE,\n",
        "    chunk_overlap=CHUNK_OVERLAP,\n",
        "    length_function=len,\n",
        "    is_separator_regex=False,\n",
        ")\n",
        "\n",
        "# 2. Embeddings (Vertex AI Embeddings)\n",
        "# Using Vertex AI's text-embedding-004 model\n",
        "embeddings = VertexAIEmbeddings(model_name=\"text-embedding-004\", project=PROJECT_ID)\n",
        "\n",
        "# 3. LLM: GPT-4 via Langchain's OpenAI integration\n",
        "# For GPT-4, ensure your OPENAI_API_KEY is set in your environment variables.\n",
        "llm = ChatOpenAI(model_name=\"gpt-4\", temperature=0) # Using GPT-4 model\n",
        "\n"
      ],
      "metadata": {
        "id": "yeI0JSPFBrNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3.Search and Retrieval**"
      ],
      "metadata": {
        "id": "zpBkbN8hB7fN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Google Search Tool (for when RAG doesn't have the answer or for general queries) ---\n",
        "# We'll use Vertex AI Search for this.\n",
        "# Ensure the Vertex AI Search Data Store is configured for web search or specific data.\n",
        "# This requires `google-cloud-discoveryengine` library.\n",
        "from google.cloud import discoveryengine_v1beta as discoveryengine\n",
        "\n",
        "class VertexAISearchTool:\n",
        "    def __init__(self, project_id: str, location: str, data_store_id: str):\n",
        "        self.project_id = project_id\n",
        "        self.location = location\n",
        "        self.data_store_id = data_store_id\n",
        "        self.client = discoveryengine.SearchServiceClient()\n",
        "        self.serving_config = self.client.serving_config_path(\n",
        "            project=self.project_id,\n",
        "            location=self.location,\n",
        "            data_store=self.data_store_id,\n",
        "            serving_config=\"default_config\",\n",
        "        )\n",
        "\n",
        "    def search(self, query: str) -> str:\n",
        "        try:\n",
        "            request = discoveryengine.SearchRequest(\n",
        "                serving_config=self.serving_config,\n",
        "                query=query,\n",
        "                page_size=3, # Retrieve top 3 results\n",
        "            )\n",
        "            response = self.client.search(request)\n",
        "\n",
        "            results = []\n",
        "            for result in response.results:\n",
        "                if result.document and result.document.derived_struct_data:\n",
        "                    snippet = result.document.derived_struct_data.get(\"snippet\", \"No snippet available.\")\n",
        "                    url = result.document.derived_struct_data.get(\"url\", \"No URL available.\")\n",
        "                    results.append(f\"Source: {url}\\nSnippet: {snippet}\")\n",
        "            if results:\n",
        "                return \"\\n\\n\".join(results)\n",
        "            else:\n",
        "                return \"No relevant information found using Google Search.\"\n",
        "        except Exception as e:\n",
        "            return f\"Error performing Vertex AI Search: {e}\"\n",
        "\n",
        "vertex_ai_search_tool = VertexAISearchTool(\n",
        "    project_id=PROJECT_ID,\n",
        "    location=REGION,\n",
        "    data_store_id=VERTEX_SEARCH_DATASTORE_ID\n",
        ")\n",
        "\n",
        "\n",
        "# --- Request Body for Chatbot API ---\n",
        "class ChatRequest(BaseModel):\n",
        "    query: str\n",
        "\n",
        "\n",
        "# --- Retrieval Setup ---\n",
        "# You'll use Vertex AI Vector Search (Matching Engine) as your vector database.\n",
        "# For this, you need to ensure your index is created and deployed.\n",
        "\n",
        "# --- Initialize Vertex AI Vector Store ---\n",
        "# In a real-time production scenario, your Vertex AI Vector Search index\n",
        "# would be pre-populated with data. This code connects to that existing index.\n",
        "try:\n",
        "    vectorstore = VertexVectorStore(\n",
        "        project_id=PROJECT_ID,\n",
        "        region=REGION,\n",
        "        index_id=VERTEX_VECTOR_SEARCH_INDEX_ID,\n",
        "        endpoint_id=VERTEX_VECTOR_SEARCH_ENDPOINT_ID,\n",
        "        embedding=embeddings,\n",
        "    )\n",
        "    retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3}) # Retrieve top 3 relevant chunks\n",
        "    print(\"Successfully connected to Vertex AI Vector Search and initialized retriever.\")\n",
        "except Exception as e:\n",
        "    print(f\"Failed to connect to Vertex AI Vector Search: {e}\")\n",
        "    print(\"Ensure your Vertex AI Vector Search index is created, deployed, and the environment variables/permissions are correct.\")\n",
        "    retriever = None # Ensure retriever is None if connection fails\n",
        "\n",
        "\n",
        "# Fallback for retriever if connection to Vertex AI Vector Search fails\n",
        "if retriever is None:\n",
        "    print(\"Warning: Retriever not initialized. Chatbot will not be able to answer context-based questions.\")\n",
        "    print(\"Falling back to only Google Search for all queries if RAG is not available.\")\n",
        "    # You might want to explicitly set a simpler LLM chain here without retrieval\n",
        "    # or handle this in the /chat endpoint directly."
      ],
      "metadata": {
        "id": "ZX5qm3VpCO7u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4.Prompt**"
      ],
      "metadata": {
        "id": "0Jvo_YH9CtRZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Prompt Template for the Chatbot\n",
        "# This template guides the LLM on how to answer questions given retrieved context.\n",
        "# Key considerations:\n",
        "# - Context: Clearly tell the LLM that the provided context is product information.\n",
        "# - Tone: Helpful, informative, slightly enthusiastic (e.g., \"We're here to help you!\").\n",
        "# - Format: Encourage structured answers (e.g., bullet points for features).\n",
        "CHATBOT_PROMPT = PromptTemplate(\n",
        "    template=\"\"\"You are a friendly and knowledgeable AI assistant for an e-commerce website.\n",
        "Your goal is to help customers find information about our products and make informed purchasing decisions.\n",
        "Use the following pieces of product information (context) to answer the user's question.\n",
        "If the answer is not found in the context, politely state that you don't have information on that specific topic\n",
        "and suggest contacting customer support for further assistance or browsing the website.\n",
        "Do not make up information.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer:\"\"\",\n",
        "    input_variables=[\"context\", \"question\"],\n",
        ")\n"
      ],
      "metadata": {
        "id": "gN5zW_EtC-DG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5.LLM Orchestration**"
      ],
      "metadata": {
        "id": "yotfN5ltCffO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm, # Now using the ChatOpenAI instance for GPT-4\n",
        "    chain_type=\"stuff\", # 'stuff' combines all documents into one prompt. 'map_reduce' etc. for more documents.\n",
        "    retriever=retriever, # This is the Vertex AI Vector Search retriever in a production setup\n",
        "    return_source_documents=True,\n",
        "    chain_type_kwargs={\"prompt\": CHATBOT_PROMPT}\n",
        ")"
      ],
      "metadata": {
        "id": "AYMgLkgsCnaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **FAST API**"
      ],
      "metadata": {
        "id": "EKC6qF7FDriC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- FastAPI App Setup ---\n",
        "app = FastAPI(\n",
        "    title=\"E-commerce Product Chatbot\",\n",
        "    description=\"An AI-powered chatbot for e-commerce product inquiries, leveraging Google Cloud's Vertex AI.\",\n",
        "    version=\"1.0.0\"\n",
        ")\n",
        "\n",
        "# Templates for serving HTML (if you want a simple frontend with FastAPI)\n",
        "templates = Jinja2Templates(directory=\"templates\")\n",
        "\n",
        "# --- Initialize Google Cloud Storage Client ---\n",
        "storage_client = storage.Client(project=PROJECT_ID)\n",
        "gcs_bucket = storage_client.bucket(GCS_BUCKET_NAME)\n",
        "\n",
        "\n",
        "# --- FastAPI Endpoints ---\n",
        "\n",
        "@app.get(\"/\", response_class=HTMLResponse)\n",
        "async def read_root(request: Request):\n",
        "    \"\"\"\n",
        "    Serves a simple HTML page for the chatbot interface.\n",
        "    \"\"\"\n",
        "    return templates.TemplateResponse(\"index.html\", {\"request\": request})\n",
        "\n",
        "\n",
        "@app.post(\"/chat\")\n",
        "async def chat_endpoint(chat_request: ChatRequest):\n",
        "    \"\"\"\n",
        "    Handles user queries, retrieves information, and generates responses.\n",
        "    \"\"\"\n",
        "    query = chat_request.query\n",
        "\n",
        "    # First, try to answer using RAG (Vector Database)\n",
        "    rag_response = None\n",
        "    if retriever:\n",
        "        try:\n",
        "            rag_result = qa_chain.invoke({\"query\": query})\n",
        "            rag_answer = rag_result.get(\"result\")\n",
        "            source_docs = rag_result.get(\"source_documents\", [])\n",
        "\n",
        "            # Check if the RAG answer indicates it couldn't find relevant info\n",
        "            # This is based on the prompt template's instruction.\n",
        "            if \"not found in the context\" in rag_answer.lower() or \"politely state that you don't have information\" in rag_answer.lower():\n",
        "                rag_response = None # RAG couldn't answer definitively\n",
        "            else:\n",
        "                rag_response = rag_answer\n",
        "                sources_info = \"\\nSources:\\n\" + \"\\n\".join([doc.metadata.get(\"source\", \"N/A\") for doc in source_docs])\n",
        "                rag_response += sources_info\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error during RAG retrieval: {e}\")\n",
        "            rag_response = None\n",
        "\n",
        "    # If RAG didn't provide a good answer, use the Google Search tool\n",
        "    final_answer = \"\"\n",
        "    if rag_response:\n",
        "        final_answer = rag_response\n",
        "    else:\n",
        "        print(f\"RAG did not provide a definitive answer for: {query}. Falling back to Google Search.\")\n",
        "        search_results = vertex_ai_search_tool.search(query)\n",
        "\n",
        "        # Combine search results with a prompt for the LLM to synthesize an answer\n",
        "        # This creates a \"tool-augmented\" RAG approach\n",
        "        if \"No relevant information found\" in search_results or \"Error performing Vertex AI Search\" in search_results:\n",
        "             final_answer = (\"I couldn't find a direct answer to your question based on our product information \"\n",
        "                             \"or general search. Please try rephrasing your question or contact our customer support for assistance.\")\n",
        "        else:\n",
        "            # Use the LLM to synthesize an answer from the search results\n",
        "            synthesis_prompt = PromptTemplate(\n",
        "                template=\"\"\"Based on the following search results, answer the user's question.\n",
        "If the search results don't contain enough information, state that.\n",
        "Search Results:\n",
        "{search_results}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer:\"\"\",\n",
        "                input_variables=[\"search_results\", \"question\"],\n",
        "            )\n",
        "            synthesis_chain = synthesis_prompt | llm\n",
        "            try:\n",
        "                final_answer = synthesis_chain.invoke({\"search_results\": search_results, \"question\": query})\n",
        "                final_answer += f\"\\n\\n(Information augmented by Google Search)\"\n",
        "            except Exception as e:\n",
        "                print(f\"Error synthesizing answer from search results: {e}\")\n",
        "                final_answer = (\"I'm sorry, I encountered an issue while trying to find information. \"\n",
        "                                \"Please try again later or contact customer support.\")\n",
        "\n",
        "    return {\"response\": final_answer}\n",
        "\n",
        "\n",
        "# --- Simple HTML Template (templates/index.html) ---\n",
        "# Create a 'templates' directory in the same location as your main.py (or app.py)\n",
        "# and put this content into index.html:\n",
        "\n",
        "\"\"\"\n",
        "<!DOCTYPE html>\n",
        "<html lang=\"en\">\n",
        "<head>\n",
        "    <meta charset=\"UTF-8\">\n",
        "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\">\n",
        "    <title>E-commerce Chatbot</title>\n",
        "    <script src=\"https://cdn.tailwindcss.com\"></script>\n",
        "    <link href=\"https://fonts.googleapis.com/css2?family=Inter:wght@400;600&display=swap\" rel=\"stylesheet\">\n",
        "    <style>\n",
        "        body {\n",
        "            font-family: 'Inter', sans-serif;\n",
        "            background-color: #f8fafc;\n",
        "        }\n",
        "        .chat-message {\n",
        "            max-width: 80%;\n",
        "            padding: 10px 15px;\n",
        "            border-radius: 20px;\n",
        "            margin-bottom: 10px;\n",
        "            word-wrap: break-word;\n",
        "        }\n",
        "        .user-message {\n",
        "            background-color: #3b82f6; /* blue-500 */\n",
        "            color: white;\n",
        "            align-self: flex-end;\n",
        "            border-bottom-right-radius: 5px;\n",
        "        }\n",
        "        .bot-message {\n",
        "            background-color: #e2e8f0; /* slate-200 */\n",
        "            color: #1e293b; /* slate-900 */\n",
        "            align-self: flex-start;\n",
        "            border-bottom-left-radius: 5px;\n",
        "        }\n",
        "        .input-area {\n",
        "            background-color: white;\n",
        "            border-top: 1px solid #e2e8f0;\n",
        "            padding: 1rem;\n",
        "        }\n",
        "    </style>\n",
        "</head>\n",
        "<body class=\"flex flex-col h-screen\">\n",
        "    <header class=\"bg-gradient-to-r from-blue-600 to-indigo-700 text-white p-4 shadow-md rounded-b-lg\">\n",
        "        <h1 class=\"text-3xl font-bold text-center\">üõçÔ∏è E-commerce Product Assistant üí¨</h1>\n",
        "        <p class=\"text-center text-sm mt-1 opacity-90\">Ask me anything about our products!</p>\n",
        "    </header>\n",
        "\n",
        "    <main class=\"flex-1 overflow-y-auto p-6 flex flex-col items-center\">\n",
        "        <div id=\"chat-box\" class=\"w-full max-w-2xl flex flex-col space-y-4\">\n",
        "            <div class=\"chat-message bot-message\">Hello! How can I help you with our products today?</div>\n",
        "        </div>\n",
        "    </main>\n",
        "\n",
        "    <footer class=\"input-area flex items-center justify-center p-4\">\n",
        "        <div class=\"w-full max-w-2xl flex rounded-full shadow-lg overflow-hidden\">\n",
        "            <input type=\"text\" id=\"user-input\" placeholder=\"Type your question here...\"\n",
        "                   class=\"flex-1 p-4 border-none focus:outline-none rounded-l-full text-lg\">\n",
        "            <button id=\"send-button\"\n",
        "                    class=\"bg-blue-600 hover:bg-blue-700 text-white font-semibold py-4 px-6 rounded-r-full\n",
        "                           transition duration-300 ease-in-out transform hover:scale-105 flex items-center justify-center\">\n",
        "                <svg xmlns=\"http://www.w3.org/2000/svg\" class=\"h-6 w-6\" fill=\"none\" viewBox=\"0 0 24 24\" stroke=\"currentColor\">\n",
        "                    <path stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2\" d=\"M14 5l7 7m0 0l-7 7m7-7H3\" />\n",
        "                </svg>\n",
        "            </button>\n",
        "        </div>\n",
        "    </footer>\n",
        "\n",
        "    <script>\n",
        "        const chatBox = document.getElementById('chat-box');\n",
        "        const userInput = document.getElementById('user-input');\n",
        "        const sendButton = document.getElementById('send-button');\n",
        "\n",
        "        function addMessage(text, sender) {\n",
        "            const messageDiv = document.createElement('div');\n",
        "            messageDiv.classList.add('chat-message');\n",
        "            if (sender === 'user') {\n",
        "                messageDiv.classList.add('user-message', 'self-end');\n",
        "            } else {\n",
        "                messageDiv.classList.add('bot-message', 'self-start');\n",
        "            }\n",
        "            messageDiv.textContent = text;\n",
        "            chatBox.appendChild(messageDiv);\n",
        "            chatBox.scrollTop = chatBox.scrollHeight; // Scroll to bottom\n",
        "        }\n",
        "\n",
        "        async function sendMessage() {\n",
        "            const query = userInput.value.trim();\n",
        "            if (!query) return;\n",
        "\n",
        "            addMessage(query, 'user');\n",
        "            userInput.value = ''; // Clear input\n",
        "\n",
        "            addMessage(\"Thinking...\", 'bot'); // Temporary thinking message\n",
        "\n",
        "            try {\n",
        "                const response = await fetch('/chat', {\n",
        "                    method: 'POST',\n",
        "                    headers: {\n",
        "                        'Content-Type': 'application/json',\n",
        "                    },\n",
        "                    body: JSON.stringify({ query: query }),\n",
        "                });\n",
        "\n",
        "                const data = await response.json();\n",
        "                // Remove \"Thinking...\" message\n",
        "                chatBox.removeChild(chatBox.lastChild);\n",
        "                addMessage(data.response, 'bot');\n",
        "            } catch (error) {\n",
        "                console.error('Error:', error);\n",
        "                chatBox.removeChild(chatBox.lastChild); // Remove thinking message\n",
        "                addMessage(\"Oops! Something went wrong. Please try again.\", 'bot');\n",
        "            }\n",
        "        }\n",
        "\n",
        "        sendButton.addEventListener('click', sendMessage);\n",
        "        userInput.addEventListener('keypress', (event) => {\n",
        "            if (event.key === 'Enter') {\n",
        "                sendMessage();\n",
        "            }\n",
        "        });\n",
        "    </script>\n",
        "</body>\n",
        "</html>\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "EWdKl0a4Dvkn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}